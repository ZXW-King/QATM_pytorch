{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from seaborn import color_palette\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import models, transforms, utils\n",
    "import copy\n",
    "from glob import glob\n",
    "import gc\n",
    "from utils import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONVERT IMAGE TO TENSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, template_dir_path, image_name, thresh_csv=None, transform=None):\n",
    "        self.transform = transform\n",
    "        if not self.transform:\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(\n",
    "                    mean=[0.485, 0.456, 0.406],\n",
    "                    std=[0.229, 0.224, 0.225],\n",
    "                )\n",
    "            ])\n",
    "        self.template_path = list(template_dir_path.iterdir())\n",
    "        self.image_name = image_name\n",
    "        \n",
    "        self.image_raw = cv2.imread(self.image_name)\n",
    "        \n",
    "        self.thresh_df = None\n",
    "        if thresh_csv:\n",
    "            self.thresh_df = pd.read_csv(thresh_csv)\n",
    "            \n",
    "        if self.transform:\n",
    "            self.image = self.transform(self.image_raw).unsqueeze(0)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.template_names)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        template_path = str(self.template_path[idx])\n",
    "        template = cv2.imread(template_path)\n",
    "        if self.transform:\n",
    "            template = self.transform(template)\n",
    "        thresh = 0.7\n",
    "        if self.thresh_df is not None:\n",
    "            if self.thresh_df.path.isin([template_path]).sum() > 0:\n",
    "                thresh = float(self.thresh_df[self.thresh_df.path==template_path].thresh)\n",
    "        return {'image': self.image, \n",
    "                    'image_raw': self.image_raw, \n",
    "                    'image_name': self.image_name,\n",
    "                    'template': template.unsqueeze(0), \n",
    "                    'template_name': template_path, \n",
    "                    'template_h': template.size()[-2],\n",
    "                   'template_w': template.size()[-1],\n",
    "                   'thresh': thresh}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_dir = 'template/'\n",
    "image_path = 'sample/sample1.jpg'\n",
    "dataset = ImageDataset(Path(template_dir), image_path, thresh_csv='thresh_template.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXTRACT FEATURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Featex():\n",
    "    def __init__(self, model, use_cuda):\n",
    "        self.use_cuda = use_cuda\n",
    "        self.feature1 = None\n",
    "        self.feature2 = None\n",
    "        self.model= copy.deepcopy(model.eval())\n",
    "        self.model = self.model[:17]\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "        if self.use_cuda:\n",
    "            self.model = self.model.cuda()\n",
    "        self.model[2].register_forward_hook(self.save_feature1)\n",
    "        self.model[16].register_forward_hook(self.save_feature2)\n",
    "        \n",
    "    def save_feature1(self, module, input, output):\n",
    "        self.feature1 = output.detach()\n",
    "    \n",
    "    def save_feature2(self, module, input, output):\n",
    "        self.feature2 = output.detach()\n",
    "        \n",
    "    def __call__(self, input, mode='big'):\n",
    "        if self.use_cuda:\n",
    "            input = input.cuda()\n",
    "        _ = self.model(input)\n",
    "        if mode=='big':\n",
    "            # resize feature1 to the same size of feature2\n",
    "            self.feature1 = F.interpolate(self.feature1, size=(self.feature2.size()[2], self.feature2.size()[3]), mode='bilinear', align_corners=True)\n",
    "        else:        \n",
    "            # resize feature2 to the same size of feature1\n",
    "            self.feature2 = F.interpolate(self.feature2, size=(self.feature1.size()[2], self.feature1.size()[3]), mode='bilinear', align_corners=True)\n",
    "        return torch.cat((self.feature1, self.feature2), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNormLayer():\n",
    "    def __call__(self, x1, x2):\n",
    "        bs, _ , H, W = x1.size()\n",
    "        _, _, h, w = x2.size()\n",
    "        x1 = x1.view(bs, -1, H*W)\n",
    "        x2 = x2.view(bs, -1, h*w)\n",
    "        concat = torch.cat((x1, x2), dim=2)\n",
    "        x_mean = torch.mean(concat, dim=2, keepdim=True)\n",
    "        x_std = torch.std(concat, dim=2, keepdim=True)\n",
    "        x1 = (x1 - x_mean) / x_std\n",
    "        x2 = (x2 - x_mean) / x_std\n",
    "        x1 = x1.view(bs, -1, H, W)\n",
    "        x2 = x2.view(bs, -1, h, w)\n",
    "        return [x1, x2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CreateModel():\n",
    "    def __init__(self, alpha, model, use_cuda):\n",
    "        self.alpha = alpha\n",
    "        self.featex = Featex(model, use_cuda)\n",
    "        self.I_feat = None\n",
    "        self.I_feat_name = None\n",
    "    def __call__(self, template, image, image_name):\n",
    "        T_feat = self.featex(template)\n",
    "        if self.I_feat_name is not image_name:\n",
    "            self.I_feat = self.featex(image)\n",
    "            self.I_feat_name = image_name\n",
    "        conf_maps = None\n",
    "        batchsize_T = T_feat.size()[0]\n",
    "        for i in range(batchsize_T):\n",
    "            T_feat_i = T_feat[i].unsqueeze(0)\n",
    "            I_feat_norm, T_feat_i = MyNormLayer()(self.I_feat, T_feat_i)\n",
    "            dist = torch.einsum(\"xcab,xcde->xabde\", I_feat_norm / torch.norm(I_feat_norm, dim=1, keepdim=True), T_feat_i / torch.norm(T_feat_i, dim=1, keepdim=True))\n",
    "            conf_map = QATM(self.alpha)(dist)\n",
    "            if conf_maps is None:\n",
    "                conf_maps = conf_map\n",
    "            else:\n",
    "                conf_maps = torch.cat([conf_maps, conf_map], dim=0)\n",
    "        return conf_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QATM():\n",
    "    def __init__(self, alpha):\n",
    "        self.alpha = alpha\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        batch_size, ref_row, ref_col, qry_row, qry_col = x.size()\n",
    "        x = x.view(batch_size, ref_row*ref_col, qry_row*qry_col)\n",
    "        xm_ref = x - torch.max(x, dim=1, keepdim=True)[0]\n",
    "        xm_qry = x - torch.max(x, dim=2, keepdim=True)[0]\n",
    "        confidence = torch.sqrt(F.softmax(self.alpha*xm_ref, dim=1) * F.softmax(self.alpha * xm_qry, dim=2))\n",
    "        conf_values, ind3 = torch.topk(confidence, 1)\n",
    "        ind1, ind2 = torch.meshgrid(torch.arange(batch_size), torch.arange(ref_row*ref_col))\n",
    "        ind1 = ind1.flatten()\n",
    "        ind2 = ind2.flatten()\n",
    "        ind3 = ind3.flatten()\n",
    "        if x.is_cuda:\n",
    "            ind1 = ind1.cuda()\n",
    "            ind2 = ind2.cuda()\n",
    "        \n",
    "        values = confidence[ind1, ind2, ind3]\n",
    "        values = torch.reshape(values, [batch_size, ref_row, ref_col, 1])\n",
    "        return values\n",
    "    def compute_output_shape( self, input_shape ):\n",
    "        bs, H, W, _, _ = input_shape\n",
    "        return (bs, H, W, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NMS AND PLOT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SINGLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nms(score, w_ini, h_ini, thresh=0.7):\n",
    "    dots = np.array(np.where(score > thresh*score.max()))\n",
    "    \n",
    "    x1 = dots[1] - w_ini//2\n",
    "    x2 = x1 + w_ini\n",
    "    y1 = dots[0] - h_ini//2\n",
    "    y2 = y1 + h_ini\n",
    "\n",
    "    areas = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "    scores = score[dots[0], dots[1]]\n",
    "    order = scores.argsort()[::-1]\n",
    "\n",
    "    keep = []\n",
    "    while order.size > 0:\n",
    "        i = order[0]\n",
    "        keep.append(i)\n",
    "        xx1 = np.maximum(x1[i], x1[order[1:]])\n",
    "        yy1 = np.maximum(y1[i], y1[order[1:]])\n",
    "        xx2 = np.minimum(x2[i], x2[order[1:]])\n",
    "        yy2 = np.minimum(y2[i], y2[order[1:]])\n",
    "\n",
    "        w = np.maximum(0.0, xx2 - xx1 + 1)\n",
    "        h = np.maximum(0.0, yy2 - yy1 + 1)\n",
    "        inter = w * h\n",
    "        ovr = inter / (areas[i] + areas[order[1:]] - inter)\n",
    "\n",
    "        inds = np.where(ovr <= 0.5)[0]\n",
    "        order = order[inds + 1]\n",
    "    boxes = np.array([[x1[keep], y1[keep]], [x2[keep], y2[keep]]]).transpose(2, 0, 1)\n",
    "    return boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_result(image_raw, boxes, show=False, save_name=None, color=(255, 0, 0)):\n",
    "    # plot result\n",
    "    d_img = image_raw.copy()\n",
    "    for box in boxes:\n",
    "        d_img = cv2.rectangle(d_img, tuple(box[0]), tuple(box[1]), color, 3)\n",
    "    if show:\n",
    "        plt.imshow(d_img[:,:,::-1])\n",
    "    if save_name:\n",
    "        cv2.imwrite(save_name, d_img)\n",
    "    return d_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MULTI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nms_multi(scores, w_array, h_array, thresh_list):\n",
    "    indices = np.arange(scores.shape[0])\n",
    "    maxes = np.max(scores.reshape(scores.shape[0], -1), axis=1)\n",
    "    # omit not-matching templates\n",
    "    scores_omit = scores[maxes > 0.1 * maxes.max()]\n",
    "    indices_omit = indices[maxes > 0.1 * maxes.max()]\n",
    "    # extract candidate pixels from scores\n",
    "    dots = None\n",
    "    dos_indices = None\n",
    "    for index, score in zip(indices_omit, scores_omit):\n",
    "        dot = np.array(np.where(score > thresh_list[index]*score.max()))\n",
    "        if dots is None:\n",
    "            dots = dot\n",
    "            dots_indices = np.ones(dot.shape[-1]) * index\n",
    "        else:\n",
    "            dots = np.concatenate([dots, dot], axis=1)\n",
    "            dots_indices = np.concatenate([dots_indices, np.ones(dot.shape[-1]) * index], axis=0)\n",
    "    dots_indices = dots_indices.astype(np.int)\n",
    "    x1 = dots[1] - w_array[dots_indices]//2\n",
    "    x2 = x1 + w_array[dots_indices]\n",
    "    y1 = dots[0] - h_array[dots_indices]//2\n",
    "    y2 = y1 + h_array[dots_indices]\n",
    "\n",
    "    areas = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "    scores = scores[dots_indices, dots[0], dots[1]]\n",
    "    order = scores.argsort()[::-1]\n",
    "    dots_indices = dots_indices[order]\n",
    "    \n",
    "    keep = []\n",
    "    keep_index = []\n",
    "    while order.size > 0:\n",
    "        i = order[0]\n",
    "        index = dots_indices[0]\n",
    "        keep.append(i)\n",
    "        keep_index.append(index)\n",
    "        xx1 = np.maximum(x1[i], x1[order[1:]])\n",
    "        yy1 = np.maximum(y1[i], y1[order[1:]])\n",
    "        xx2 = np.minimum(x2[i], x2[order[1:]])\n",
    "        yy2 = np.minimum(y2[i], y2[order[1:]])\n",
    "\n",
    "        w = np.maximum(0.0, xx2 - xx1 + 1)\n",
    "        h = np.maximum(0.0, yy2 - yy1 + 1)\n",
    "        inter = w * h\n",
    "        ovr = inter / (areas[i] + areas[order[1:]] - inter)\n",
    "\n",
    "        inds = np.where(ovr <= 0.05)[0]\n",
    "        order = order[inds + 1]\n",
    "        dots_indices = dots_indices[inds + 1]\n",
    "        \n",
    "    boxes = np.array([[x1[keep], y1[keep]], [x2[keep], y2[keep]]]).transpose(2,0,1)\n",
    "    return boxes, np.array(keep_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_result_multi(image_raw, boxes, indices, show=False, save_name=None, color_list=None):\n",
    "    d_img = image_raw.copy()\n",
    "    if color_list is None:\n",
    "        color_list = color_palette(\"hls\", indices.max()+1)\n",
    "        color_list = list(map(lambda x: (int(x[0]*255), int(x[1]*255), int(x[2]*255)), color_list))\n",
    "    for i in range(len(indices)):\n",
    "        d_img = plot_result(d_img, boxes[i][None, :,:].copy(), color=color_list[indices[i]])\n",
    "    if show:\n",
    "        plt.imshow(d_img[:,:,::-1])\n",
    "    if save_name:\n",
    "        cv2.imwrite(save_name, d_img)\n",
    "    return d_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUNNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_one_sample(model, template, image, image_name):\n",
    "    val = model(template, image, image_name)\n",
    "    if val.is_cuda:\n",
    "        val = val.cpu()\n",
    "    val = val.numpy()\n",
    "    val = np.log(val)\n",
    "    \n",
    "    batch_size = val.shape[0]\n",
    "    scores = []\n",
    "    for i in range(batch_size):\n",
    "        # compute geometry average on score map\n",
    "        gray = val[i,:,:,0]\n",
    "        gray = cv2.resize( gray, (image.size()[-1], image.size()[-2]) )\n",
    "        h = template.size()[-2]\n",
    "        w = template.size()[-1]\n",
    "        score = compute_score( gray, w, h) \n",
    "        score[score>-1e-7] = score.min()\n",
    "        score = np.exp(score / (h*w)) # reverse number range back after computing geometry average\n",
    "        scores.append(score)\n",
    "    return np.array(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_multi_sample(model, dataset):\n",
    "    scores = None\n",
    "    w_array = []\n",
    "    h_array = []\n",
    "    thresh_list = []\n",
    "    for data in dataset:\n",
    "        score = run_one_sample(model, data['template'], data['image'], data['image_name'])\n",
    "        if scores is None:\n",
    "            scores = score\n",
    "        else:\n",
    "            scores = np.concatenate([scores, score], axis=0)\n",
    "        w_array.append(data['template_w'])\n",
    "        h_array.append(data['template_h'])\n",
    "        thresh_list.append(data['thresh'])\n",
    "    return np.array(scores), np.array(w_array), np.array(h_array), thresh_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CreateModel(model=models.vgg19(pretrained=True).features, alpha=25, use_cuda=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores, w_array, h_array, thresh_list = run_multi_sample(model, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes, indices = nms_multi(scores, w_array, h_array, thresh_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_img = plot_result_multi(dataset.image_raw, boxes, indices, show=True, save_name='result_sample.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(scores[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running with Multi Samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_dir = 'template/'\n",
    "image_dir = 'sample2/'\n",
    "result_path = 'result2/'\n",
    "if not os.path.isdir(result_path):\n",
    "    os.mkdir(result_path)\n",
    "\n",
    "images = glob(os.path.join(image_dir,'*'))\n",
    "\n",
    "i=1\n",
    "for image in images:\n",
    "    print('-----',i,'/',len(images),'-----')\n",
    "    image_name = image.split('/')[-1].split('.')[0]\n",
    "    print('Sample Image:',image_name,' is Processing...')\n",
    "    dataset = ImageDataset(Path(template_dir), image, thresh_csv='thresh_template.csv')\n",
    "    print(\"calculate score...\")\n",
    "    scores, w_array, h_array, thresh_list = run_multi_sample(model, dataset)\n",
    "    print(\"nms...\")\n",
    "    boxes, indices = nms_multi(scores, w_array, h_array, thresh_list)\n",
    "    d_img = plot_result_multi(dataset.image_raw, boxes, indices, show=True, save_name= os.path.join(result_path, image_name)+'.png')\n",
    "    print(\"result image was saved\")\n",
    "\n",
    "    del(dataset)\n",
    "    del(d_img)\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    i+=1\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
